<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>hadoop安装教程3</title>
      <link href="/posts/3d90c307.html"/>
      <url>/posts/3d90c307.html</url>
      
        <content type="html"><![CDATA[<h1 id="hadoop伪集群安装"><a href="#hadoop伪集群安装" class="headerlink" title="hadoop伪集群安装"></a>hadoop伪集群安装</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h1 id="一、安装hadoop"><a href="#一、安装hadoop" class="headerlink" title="一、安装hadoop"></a>一、安装hadoop</h1><h2 id="1-用xftp传输hadoop安装包到hadoop1中"><a href="#1-用xftp传输hadoop安装包到hadoop1中" class="headerlink" title="1.用xftp传输hadoop安装包到hadoop1中"></a>1.用xftp传输hadoop安装包到hadoop1中</h2><p><img src="/posts/3d90c307/chuanshu3.png" alt="chuanshu3"></p><h2 id="2-解压hadoop包"><a href="#2-解压hadoop包" class="headerlink" title="2.解压hadoop包"></a>2.解压hadoop包</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 app]$ cd /home/hadoop/app/</span><br><span class="line">[hadoop@hadoop1 app]$ tar -zxvf hadoop-3.3.3.tar.gz</span><br></pre></td></tr></table></figure><h2 id="3-创建软链接"><a href="#3-创建软链接" class="headerlink" title="3.创建软链接"></a>3.创建软链接</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 app]$ ln -s hadoop-3.3.3 hadoop</span><br></pre></td></tr></table></figure><h2 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4.配置环境变量"></a>4.配置环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 profile.d]$ vi ~/.bashrc</span><br><span class="line"># .bashrc</span><br><span class="line"></span><br><span class="line"># Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">        . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line"># export SYSTEMD_PAGER=</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export ZOO_HOME=/home/hadoop/app/zookeeper</span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH</span><br><span class="line">export HADOOP_HOME=/home/hadoop/app/hadoop#添加以下内容</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH#添加以下内容</span><br><span class="line"># User specific aliases and functions     </span><br></pre></td></tr></table></figure><h2 id="5-刷新环境变量"><a href="#5-刷新环境变量" class="headerlink" title="5.刷新环境变量"></a>5.刷新环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 profile.d]$ source ~/.bashrc</span><br></pre></td></tr></table></figure><h2 id="6-配置环境变量"><a href="#6-配置环境变量" class="headerlink" title="6.配置环境变量"></a>6.配置环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ vi /home/hadoop/app/hadoop/etc/hadoop/hadoop-env.sh#找到以下内容，修改第54行，保存</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     44 # Generic settings for HADOOP</span><br><span class="line">     45 ###</span><br><span class="line">     46 </span><br><span class="line">     47 # Technically, the only required environment variable is JAVA_HOME.</span><br><span class="line">     48 # All others are optional.  However, the defaults are probably not</span><br><span class="line">     49 # preferred.  Many sites configure these options outside of Hadoop,</span><br><span class="line">     50 # such as in /etc/profile.d</span><br><span class="line">     51 </span><br><span class="line">     52 # The java implementation to use. By default, this environment</span><br><span class="line">     53 # variable is REQUIRED on ALL platforms except OS X!</span><br><span class="line">     54 export JAVA_HOME=/home/hadoop/app/jdk#修改此行</span><br><span class="line">     55 </span><br><span class="line">     56 # Location of Hadoop.  By default, Hadoop will attempt to determine</span><br><span class="line">     57 # this location based upon its execution path.</span><br><span class="line">     58 # export HADOOP_HOME=</span><br><span class="line">     59 </span><br><span class="line">     60 # Location of Hadoop&#x27;s configuration information.  i.e., where this</span><br><span class="line">     61 # file is living. If this is not defined, Hadoop will attempt to</span><br><span class="line">     62 # locate it based upon its execution path.</span><br><span class="line">     63 #</span><br></pre></td></tr></table></figure><h2 id="7-刷新环境变量"><a href="#7-刷新环境变量" class="headerlink" title="7.刷新环境变量"></a>7.刷新环境变量</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ source hadoop-env.sh</span><br></pre></td></tr></table></figure><h2 id="8-查看hadoop安装情况"><a href="#8-查看hadoop安装情况" class="headerlink" title="8.查看hadoop安装情况"></a>8.查看hadoop安装情况</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ hadoop version</span><br><span class="line">Hadoop 3.3.3#有显示hadoop则安装成功</span><br><span class="line">Source code repository https://github.com/apache/hadoop.git -r d37586cbda38c338d9fe481addda5a05fb516f71</span><br><span class="line">Compiled by stevel on 2022-05-09T16:36Z</span><br><span class="line">Compiled with protoc 3.7.1</span><br><span class="line">From source with checksum eb96dd4a797b6989ae0cdb9db6efc6</span><br><span class="line">This command was run using /home/hadoop/app/hadoop-3.3.3/share/hadoop/common/hadoop-common-3.3.3.jar</span><br></pre></td></tr></table></figure><h2 id="9-重启主机"><a href="#9-重启主机" class="headerlink" title="9.重启主机"></a>9.重启主机</h2><h1 id="二、创建规划目录"><a href="#二、创建规划目录" class="headerlink" title="二、创建规划目录"></a>二、创建规划目录</h1><h2 id="1-创建hadoop-recoed文件夹"><a href="#1-创建hadoop-recoed文件夹" class="headerlink" title="1.创建hadoop-recoed文件夹"></a>1.创建hadoop-recoed文件夹</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 data]$ mkdir /home/hadoop/data/hadoop-record</span><br></pre></td></tr></table></figure><h2 id="2-进入hadoop-recoed创建四个文件夹"><a href="#2-进入hadoop-recoed创建四个文件夹" class="headerlink" title="2.进入hadoop-recoed创建四个文件夹"></a>2.进入hadoop-recoed创建四个文件夹</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 data]$ cd /home/hadoop/data/hadoop-record/</span><br><span class="line">[hadoop@hadoop1 hadoop-record]$ mkdir data name secondary tmp</span><br><span class="line">[hadoop@hadoop1 hadoop-record]$ ls</span><br><span class="line">data  name  secondary  tmp</span><br></pre></td></tr></table></figure><h1 id="三、配置文件"><a href="#三、配置文件" class="headerlink" title="三、配置文件"></a>三、配置文件</h1><h2 id="1-配置core-site-xml"><a href="#1-配置core-site-xml" class="headerlink" title="1.配置core-site.xml"></a>1.配置core-site.xml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ vi /home/hadoop/app/hadoop/etc/hadoop/core-site.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line">#添加以下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://hadoop1:9000&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;file:///home/hadoop/data/hadoop-record/tmp&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-配置hdfs-site-xml"><a href="#2-配置hdfs-site-xml" class="headerlink" title="2.配置hdfs-site.xml"></a>2.配置hdfs-site.xml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ vi /home/hadoop/app/hadoop/etc/hadoop/hdfs-site.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">#添加以下内容</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;file:///home/hadoop/data/hadoop-record/name&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.dataname.data.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;file:///home/hadoop/data/hadoop-record/data&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="3-配置mapred-site-xml"><a href="#3-配置mapred-site-xml" class="headerlink" title="3.配置mapred-site.xml"></a>3.配置mapred-site.xml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">注意此处有个别hadoop没有mapred-site.xml，但是有mapred-site.xml.template，需要运行以下代码cp /home/hadoop/app/hadoop/etc/hadoop/mapred-site.xml.template mapred-site.xml</span><br><span class="line">[hadoop@hadoop1 hadoop]$ vi /home/hadoop/app/hadoop/etc/hadoop/mapred-site.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line">#添加以下代码</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="4-配置yarn-site-xml"><a href="#4-配置yarn-site-xml" class="headerlink" title="4.配置yarn-site.xml"></a>4.配置yarn-site.xml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ vi /home/hadoop/app/hadoop/etc/hadoop/yarn-site.xml</span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">#添加以下内容</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line"></span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hadoop1&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h1 id="四、启动伪集群"><a href="#四、启动伪集群" class="headerlink" title="四、启动伪集群"></a>四、启动伪集群</h1><h2 id="1-格式化HDFS"><a href="#1-格式化HDFS" class="headerlink" title="1.格式化HDFS"></a>1.格式化HDFS</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure><h2 id="2-启动文件系统"><a href="#2-启动文件系统" class="headerlink" title="2.启动文件系统"></a>2.启动文件系统</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ start-dfs.sh</span><br></pre></td></tr></table></figure><h2 id="3-启动yarn调度"><a href="#3-启动yarn调度" class="headerlink" title="3.启动yarn调度"></a>3.启动yarn调度</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ start-yarn.sh</span><br></pre></td></tr></table></figure><h2 id="4-查看节点"><a href="#4-查看节点" class="headerlink" title="4.查看节点"></a>4.查看节点</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ jps</span><br><span class="line">2273 SecondaryNameNode</span><br><span class="line">3507 Jps</span><br><span class="line">1972 NameNode</span><br><span class="line">2532 ResourceManager</span><br><span class="line">2086 DataNode</span><br><span class="line">2639 NodeManager</span><br></pre></td></tr></table></figure><h2 id="5-用本机浏览器输入"><a href="#5-用本机浏览器输入" class="headerlink" title="5.用本机浏览器输入"></a>5.用本机浏览器输入</h2><p>（1）查看HDFS的NameNode：<br>注意：如果用的是hadoop2.x的版本，那么端口是50070，如果用的是hadoop3.x的版本，那么端口是9870<br>在本机浏览器输入：hadoop1的ip地址：50070<br>例如192.168.x.x:50070<br>出现以下网页为伪集群搭建成功<br><img src="/posts/3d90c307/tu1.png" alt="tu1"><br>（2）查看YARN的ResourceManager：<a href="http://hadoop1:8088">http://hadoop1:8088</a><br><img src="/posts/3d90c307/tu2.png" alt="tu2"></p>]]></content>
      
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hadoop安装教程2</title>
      <link href="/posts/4a97f391.html"/>
      <url>/posts/4a97f391.html</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><h1 id="搭建zookeeper集群部署"><a href="#搭建zookeeper集群部署" class="headerlink" title="搭建zookeeper集群部署"></a>搭建zookeeper集群部署</h1><h1 id="所需软件"><a href="#所需软件" class="headerlink" title="所需软件"></a>所需软件</h1><p>jdk<br>zookeeper<br>xftp7<br>软件链接：<a href="https://pan.baidu.com/s/10Qw0W9RfyFGHC971Q1_DPQ">https://pan.baidu.com/s/10Qw0W9RfyFGHC971Q1_DPQ</a><br>        提取码：vgha</p><h1 id="一、安装jdk"><a href="#一、安装jdk" class="headerlink" title="一、安装jdk"></a>一、安装jdk</h1><h2 id="hadoop1操作"><a href="#hadoop1操作" class="headerlink" title="hadoop1操作"></a>hadoop1操作</h2><h3 id="1-创建jdk所需目录"><a href="#1-创建jdk所需目录" class="headerlink" title="1.创建jdk所需目录"></a>1.创建jdk所需目录</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdata -p</span><br><span class="line">[hadoop@hadoop1 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdatalog -p</span><br><span class="line">[hadoop@hadoop1 zookeeper]$ cd /home/hadoop/data/zookeeper #进入创建的目录</span><br><span class="line">[hadoop@hadoop1 zookeeper]$ ll#查看创建的目录</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdata</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdatalog</span><br></pre></td></tr></table></figure><h3 id="2-通过xftp7将文件上传到指定目录中"><a href="#2-通过xftp7将文件上传到指定目录中" class="headerlink" title="2.通过xftp7将文件上传到指定目录中"></a>2.通过xftp7将文件上传到指定目录中</h3><p><img src="/posts/4a97f391/tupian1.png" alt="tupian1"></p><h3 id="3-查看上传的文件，解压jdk"><a href="#3-查看上传的文件，解压jdk" class="headerlink" title="3.查看上传的文件，解压jdk"></a>3.查看上传的文件，解压jdk</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#查看文件</span><br><span class="line">[hadoop@hadoop1 zookeeper]$ cd /home/hadoop/app</span><br><span class="line">[hadoop@hadoop1 app]$ ll#查看刚才上传的文件</span><br><span class="line">总用量 198460</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br><span class="line">#在hadoop1上解压jdk</span><br><span class="line">[hadoop@hadoop1 app]$ tar -zxvf jdk-8u141-linux-x64.tar.gz  #解压jdk</span><br><span class="line">[hadoop@hadoop1 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="3-编辑环境变量"><a href="#3-编辑环境变量" class="headerlink" title="3.编辑环境变量"></a>3.编辑环境变量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 app]$ ln -s jdk.1.8.0_141/ jdk#给jdk1.8.0_141创建软连接</span><br><span class="line">[hadoop@hadoop1 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">lrwxrwxrwx. 1 hadoop hadoop        14 10月  8 15:36 jdk -&gt; jdk.1.8.0_141/</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line">[hadoop@hadoop1 app]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line">      1 # .bashrc</span><br><span class="line">      2 </span><br><span class="line">      3 # Source global definitions</span><br><span class="line">      4 if [ -f /etc/bashrc ]; then</span><br><span class="line">      5         . /etc/bashrc</span><br><span class="line">      6 fi</span><br><span class="line">      7 </span><br><span class="line">      8 # Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line">      9 # export SYSTEMD_PAGER=</span><br><span class="line">     10 export JAVA_HOME=/home/hadoop/app/jdk#添加此行</span><br><span class="line">     11 export PATH=$JAVA_HOME/bin:$PATH#添加此行</span><br><span class="line">     12 # User specific aliases and functions</span><br><span class="line">#添加10、11行内容，保存。</span><br><span class="line">#刷新环境变量</span><br><span class="line">[hadoop@hadoop1 app]$ source ~/.bashrc</span><br><span class="line">[hadoop@hadoop1 app]$ java -version</span><br><span class="line">java version &quot;1.8.0_141&quot;#出现此代码就是配置成功</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_141-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</span><br></pre></td></tr></table></figure><h3 id="4-将jdk拷贝到hadoop2和hadoop3"><a href="#4-将jdk拷贝到hadoop2和hadoop3" class="headerlink" title="4.将jdk拷贝到hadoop2和hadoop3"></a>4.将jdk拷贝到hadoop2和hadoop3</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 app]$ scp -r jdk1.8.0_141 hadoop@hadoop2:/home/hadoop/app</span><br><span class="line">[hadoop@hadoop1 app]$ scp -r jdk1.8.0_141 hadoop@hadoop3:/home/hadoop/app</span><br></pre></td></tr></table></figure><h2 id="hadoop2操作"><a href="#hadoop2操作" class="headerlink" title="hadoop2操作"></a>hadoop2操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#创建规划目录</span><br><span class="line">[hadoop@hadoop2 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdata -p</span><br><span class="line">[hadoop@hadoop2 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdatalog -p</span><br><span class="line">[hadoop@hadoop2 zookeeper]$ cd /home/hadoop/data/zookeeper #进入创建的目录</span><br><span class="line">[hadoop@hadooop2 zookeeper]$ ll#查看创建的目录</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdata</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdatalog</span><br><span class="line"></span><br><span class="line">在hadoop2上解压jdk</span><br><span class="line">[hadoop@hadoop2 app]$cd /home/hadoop/app</span><br><span class="line">[hadoop@hadoop2 app]$ tar -zxvf jdk-8u141-linux-x64.tar.gz  #解压jdk</span><br><span class="line">[hadoop@hadoop2 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br><span class="line">#编辑环境变量</span><br><span class="line">[hadoop@hadoop2 app]$ ln -s jdk.1.8.0_141/ jdk#给jdk1.8.0_141创建软连接</span><br><span class="line">[hadoop@hadoop2 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">lrwxrwxrwx. 1 hadoop hadoop        14 10月  8 15:36 jdk -&gt; jdk.1.8.0_141/</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line">[hadoop@hadoop2 app]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line">      1 # .bashrc</span><br><span class="line">      2 </span><br><span class="line">      3 # Source global definitions</span><br><span class="line">      4 if [ -f /etc/bashrc ]; then</span><br><span class="line">      5         . /etc/bashrc</span><br><span class="line">      6 fi</span><br><span class="line">      7 </span><br><span class="line">      8 # Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line">      9 # export SYSTEMD_PAGER=</span><br><span class="line">     10 export JAVA_HOME=/home/hadoop/app/jdk  #添加此行</span><br><span class="line">     11 export PATH=$JAVA_HOME/bin:$PATH#添加此行</span><br><span class="line">     12 # User specific aliases and functions</span><br><span class="line">#添加10、11行内容，保存。</span><br><span class="line"></span><br><span class="line">#刷新环境变量</span><br><span class="line">[hadoop@hadoop2 app]$ source ~/.bashrc</span><br><span class="line">[hadoop@hadoop2 app]$ java -version</span><br><span class="line">java version &quot;1.8.0_141&quot;#出现此代码就是配置成功</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_141-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</span><br></pre></td></tr></table></figure><h2 id="hadoop3操作"><a href="#hadoop3操作" class="headerlink" title="hadoop3操作"></a>hadoop3操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#创建规划目录</span><br><span class="line">[hadoop@hadoop3 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdata -p</span><br><span class="line">[hadoop@hadoop3 yxs]$ mkdir /home/hadoop/data/zookeeper/zkdatalog -p</span><br><span class="line">[hadoop@hadoop3 zookeeper]$ cd /home/hadoop/data/zookeeper #进入创建的目录</span><br><span class="line">[hadoop@hadoop3 zookeeper]$ ll#查看创建的目录</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdata</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop 6 10月  8 14:56 zkdatalog</span><br><span class="line"></span><br><span class="line">在hadoop3上解压jdk</span><br><span class="line">[hadoop@hadoop3 app]$cd /home/hadoop/app</span><br><span class="line">[hadoop@hadoop3 app]$ tar -zxvf jdk-8u141-linux-x64.tar.gz  #解压jdk</span><br><span class="line">[hadoop@hadoop3 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br><span class="line">#编辑环境变量</span><br><span class="line">[hadoop@hadoop3 app]$ ln -s jdk.1.8.0_141/ jdk#给jdk1.8.0_141创建软连接</span><br><span class="line">[hadoop@hadoop3 app]$ ll</span><br><span class="line">总用量 198460</span><br><span class="line">lrwxrwxrwx. 1 hadoop hadoop        14 10月  8 15:36 jdk -&gt; jdk.1.8.0_141/</span><br><span class="line">drwxr-xr-x. 8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">-rw-rw-r--. 1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line">[hadoop@hadoop3 app]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line">      1 # .bashrc</span><br><span class="line">      2 </span><br><span class="line">      3 # Source global definitions</span><br><span class="line">      4 if [ -f /etc/bashrc ]; then</span><br><span class="line">      5         . /etc/bashrc</span><br><span class="line">      6 fi</span><br><span class="line">      7 </span><br><span class="line">      8 # Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line">      9 # export SYSTEMD_PAGER=</span><br><span class="line">     10 export JAVA_HOME=/home/hadoop/app/jdk#添加此行</span><br><span class="line">     11 export PATH=$JAVA_HOME/bin:$PATH#添加此行</span><br><span class="line">     12 # User specific aliases and functions</span><br><span class="line">#添加10、11行内容，保存。</span><br><span class="line"></span><br><span class="line">#刷新环境变量</span><br><span class="line">[hadoop@hadoop3 app]$ source ~/.bashrc</span><br><span class="line">[hadoop@hadoop3 app]$ java -version</span><br><span class="line">java version &quot;1.8.0_141&quot;#出现此代码就是配置成功</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_141-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.141-b15, mixed mode)</span><br></pre></td></tr></table></figure><h1 id="二、安装zookeeper"><a href="#二、安装zookeeper" class="headerlink" title="二、安装zookeeper"></a>二、安装zookeeper</h1><h2 id="hadoop1操作-1"><a href="#hadoop1操作-1" class="headerlink" title="hadoop1操作"></a>hadoop1操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">#1.解压zookeeper压缩包（此处需进入先/home/hadoop/app目录下）</span><br><span class="line">[hadoop@hadoop1 app]$ tar -zxvf zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br><span class="line">#2.创建软链接（此处需先进入/home/hadoop/app目录下）</span><br><span class="line">[hadoop@hadoop1 app]$ ln -s zookeeper-3.4.6 zookeeper</span><br><span class="line">[hadoop@hadoop1 app]$ ll</span><br><span class="line">总用量 198464</span><br><span class="line">lrwxrwxrwx.  1 hadoop hadoop        13 10月  8 16:14 jdk -&gt; jdk1.8.0_141/</span><br><span class="line">drwxr-xr-x.  8 hadoop hadoop       255 7月  12 2017 jdk1.8.0_141</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop 185516505 10月  8 15:19 jdk-8u141-linux-x64.tar.gz</span><br><span class="line">lrwxrwxrwx.  1 hadoop hadoop        15 10月  8 16:23 zookeeper -&gt; zookeeper-3.4.6</span><br><span class="line">drwxr-xr-x. 10 hadoop hadoop      4096 2月  20 2014 zookeeper-3.4.6</span><br><span class="line">-rw-rw-r--.  1 hadoop hadoop  17699306 10月  8 15:19 zookeeper-3.4.6.tar.gz</span><br><span class="line"></span><br><span class="line">#3.复制zoo_sample.cfg 改名为zoo.cfg</span><br><span class="line">[hadoop@hadoop1 conf]$ cp /home/hadoop/app/zookeeper/conf/zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">#4.修改配置文件</span><br><span class="line">[hadoop@hadoop1 conf]$ vi /home/hadoop/app/zookeeper/conf/zoo.cfg #修改和添加以下内容</span><br><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line">      4 # synchronization phase can take</span><br><span class="line">      5 initLimit=10</span><br><span class="line">      6 # The number of ticks that can pass between</span><br><span class="line">      7 # sending a request and getting an acknowledgement</span><br><span class="line">      8 syncLimit=5</span><br><span class="line">      9 # the directory where the snapshot is stored.</span><br><span class="line">     10 # do not use /tmp for storage, /tmp here is just</span><br><span class="line">     11 # example sakes.</span><br><span class="line">     12 dataDir=/home/hadoop/data/zookeeper/zkdata#添加此行</span><br><span class="line">     13 dataLogDir=/home/hadoop/data/zookeeper/zkdatalog#添加此行</span><br><span class="line">     14 # the port at which the clients will connect</span><br><span class="line">     15 clientPort=2181</span><br><span class="line">     16 # the maximum number of client connections.</span><br><span class="line">     17 # increase this if you need to handle more clients</span><br><span class="line">     18 #maxClientCnxns=60</span><br><span class="line">     19 # </span><br><span class="line">     20 # Be sure to read the maintenance section of the </span><br><span class="line">     21 # administrator guide before turning on autopurge.</span><br><span class="line">     22 #</span><br><span class="line">     23 # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenanc        e</span><br><span class="line">     24 # </span><br><span class="line">     25 # The number of snapshots to retain in dataDir</span><br><span class="line">     26 #autopurge.snapRetainCount=3</span><br><span class="line">     27 # Purge task interval in hours</span><br><span class="line">     28 # Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">     29 #autopurge.purgeInterval=1</span><br><span class="line">     30 server.1=hadoop1:2888:3888#hadoop1为主机名，hostname命令查询</span><br><span class="line">     31 server.2=hadoop2:2888:3888#添加此行</span><br><span class="line">     32 server.3=hadoop3:2888:3888#添加此行</span><br><span class="line"></span><br><span class="line">5.配置myid</span><br><span class="line">[hadoop@hadoop1 conf]$ vi /home/hadoop/data/zookeeper/zkdata/myid</span><br><span class="line">1#在编辑器添加1</span><br><span class="line"></span><br><span class="line">6.添加环境变量</span><br><span class="line">[hadoop@hadoop1 zookeeper]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"># .bashrc</span><br><span class="line"></span><br><span class="line"># Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">        . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line"># export SYSTEMD_PAGER=</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export ZOO_HOME=/home/hadoop/app/zookeeper#添加此行内容</span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH#添加此行内容</span><br><span class="line"># User specific aliases and functions</span><br><span class="line">~  </span><br><span class="line">#7.刷新环境变量</span><br><span class="line">[hadoop@hadoop1 app]$ source ~/.bashrc               </span><br><span class="line"></span><br><span class="line">8.将zookeeper拷贝到hadoop2和hadoop3中</span><br><span class="line">#进入目录</span><br><span class="line">[hadoop@master zookeeper]$ cd /etc/init.d</span><br><span class="line">#拷贝到hadoop2、hadoop3</span><br><span class="line">[hadoop@hadoop1 app]$ scp -r zookeeper-3.4.6 hadoop@hadoop2:/home/hadoop/app/</span><br><span class="line">[hadoop@hadoop1 app]$ scp -r zookeeper-3.4.6 hadoop@hadoop3:/home/hadoop/app/</span><br></pre></td></tr></table></figure><h2 id="hadoop2操作-1"><a href="#hadoop2操作-1" class="headerlink" title="hadoop2操作"></a>hadoop2操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#1.#创建软链接（此处需先进入/home/hadoop/app目录下）</span><br><span class="line">[hadoop@hadoop2 app]$ ln -s zookeeper-3.4.6/ zookeeper</span><br><span class="line"></span><br><span class="line">#2.复制zoo_sample.cfg 改名为zoo.cfg</span><br><span class="line">[hadoop@hadoop2 conf]$ cp /home/hadoop/app/zookeeper/conf/zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">#3.修改配置文件</span><br><span class="line">[hadoop@hadoop2 conf]$ vi /home/hadoop/app/zookeeper/conf/zoo.cfg #修改和添加以下内容</span><br><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line">      4 # synchronization phase can take</span><br><span class="line">      5 initLimit=10</span><br><span class="line">      6 # The number of ticks that can pass between</span><br><span class="line">      7 # sending a request and getting an acknowledgement</span><br><span class="line">      8 syncLimit=5</span><br><span class="line">      9 # the directory where the snapshot is stored.</span><br><span class="line">     10 # do not use /tmp for storage, /tmp here is just</span><br><span class="line">     11 # example sakes.</span><br><span class="line">     12 dataDir=/home/hadoop/data/zookeeper/zkdata#添加此行</span><br><span class="line">     13 dataLogDir=/home/hadoop/data/zookeeper/zkdatalog#添加此行</span><br><span class="line">     14 # the port at which the clients will connect</span><br><span class="line">     15 clientPort=2181</span><br><span class="line">     16 # the maximum number of client connections.</span><br><span class="line">     17 # increase this if you need to handle more clients</span><br><span class="line">     18 #maxClientCnxns=60</span><br><span class="line">     19 # </span><br><span class="line">     20 # Be sure to read the maintenance section of the </span><br><span class="line">     21 # administrator guide before turning on autopurge.</span><br><span class="line">     22 #</span><br><span class="line">     23 # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenanc        e</span><br><span class="line">     24 # </span><br><span class="line">     25 # The number of snapshots to retain in dataDir</span><br><span class="line">     26 #autopurge.snapRetainCount=3</span><br><span class="line">     27 # Purge task interval in hours</span><br><span class="line">     28 # Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">     29 #autopurge.purgeInterval=1</span><br><span class="line">     30 server.1=hadoop1:2888:3888#hadoop1为主机名，hostname命令查询</span><br><span class="line">     31 server.2=hadoop2:2888:3888#添加此行</span><br><span class="line">     32 server.3=hadoop3:2888:3888#添加此行</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#4.配置myid</span><br><span class="line">[hadoop@hadoop2 conf]$ vi /home/hadoop/data/zookeeper/zkdata/myid</span><br><span class="line">2  #在编辑器添加2</span><br><span class="line"></span><br><span class="line">#5.添加环境变量</span><br><span class="line">[hadoop@hadoop2 app]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"># .bashrc</span><br><span class="line"></span><br><span class="line"># Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">        . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line"># export SYSTEMD_PAGER=</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export ZOO_HOME=/home/hadoop/app/zookeeper#添加此行内容</span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH#添加此行内容</span><br><span class="line"># User specific aliases and functions</span><br><span class="line"></span><br><span class="line">#6.刷新环境变量</span><br><span class="line">[hadoop@hadoop2 app]$ source ~/.bashrc</span><br></pre></td></tr></table></figure><h2 id="hadoop3操作-1"><a href="#hadoop3操作-1" class="headerlink" title="hadoop3操作"></a>hadoop3操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">#1.创建软链接（此处需先进入/home/hadoop/app目录下）</span><br><span class="line">[hadoop@hadoop3 app]$ ln -s zookeeper-3.4.6/ zookeeper</span><br><span class="line"></span><br><span class="line">#2.复制zoo_sample.cfg 改名为zoo.cfg</span><br><span class="line">[hadoop@hadoop3 conf]$ cp /home/hadoop/app/zookeeper/conf/zoo_sample.cfg zoo.cfg</span><br><span class="line"></span><br><span class="line">#3.修改配置文件</span><br><span class="line">[hadoop@hadoop3 conf]$ vi /home/hadoop/app/zookeeper/conf/zoo.cfg #修改和添加以下内容</span><br><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line">      4 # synchronization phase can take</span><br><span class="line">      5 initLimit=10</span><br><span class="line">      6 # The number of ticks that can pass between</span><br><span class="line">      7 # sending a request and getting an acknowledgement</span><br><span class="line">      8 syncLimit=5</span><br><span class="line">      9 # the directory where the snapshot is stored.</span><br><span class="line">     10 # do not use /tmp for storage, /tmp here is just</span><br><span class="line">     11 # example sakes.</span><br><span class="line">     12 dataDir=/home/hadoop/data/zookeeper/zkdata#添加此行</span><br><span class="line">     13 dataLogDir=/home/hadoop/data/zookeeper/zkdatalog#添加此行</span><br><span class="line">     14 # the port at which the clients will connect</span><br><span class="line">     15 clientPort=2181</span><br><span class="line">     16 # the maximum number of client connections.</span><br><span class="line">     17 # increase this if you need to handle more clients</span><br><span class="line">     18 #maxClientCnxns=60</span><br><span class="line">     19 # </span><br><span class="line">     20 # Be sure to read the maintenance section of the </span><br><span class="line">     21 # administrator guide before turning on autopurge.</span><br><span class="line">     22 #</span><br><span class="line">     23 # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenanc        e</span><br><span class="line">     24 # </span><br><span class="line">     25 # The number of snapshots to retain in dataDir</span><br><span class="line">     26 #autopurge.snapRetainCount=3</span><br><span class="line">     27 # Purge task interval in hours</span><br><span class="line">     28 # Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">     29 #autopurge.purgeInterval=1</span><br><span class="line">     30 server.1=hadoop1:2888:3888#hadoop1为主机名，hostname命令查询</span><br><span class="line">     31 server.2=hadoop2:2888:3888#添加此行</span><br><span class="line">     32 server.3=hadoop3:2888:3888#添加此行</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#4.配置myid</span><br><span class="line">[hadoop@hadoop3 conf]$ vi /home/hadoop/data/zookeeper/zkdata/myid</span><br><span class="line">3  #在编辑器添加3</span><br><span class="line"></span><br><span class="line">#5.添加环境变量</span><br><span class="line">[hadoop@hadoop3 app]$ vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"># .bashrc</span><br><span class="line"></span><br><span class="line"># Source global definitions</span><br><span class="line">if [ -f /etc/bashrc ]; then</span><br><span class="line">        . /etc/bashrc</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># Uncomment the following line if you don&#x27;t like systemctl&#x27;s auto-paging feature:</span><br><span class="line"># export SYSTEMD_PAGER=</span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export ZOO_HOME=/home/hadoop/app/zookeeper#添加此行内容</span><br><span class="line">export PATH=$ZOO_HOME/bin:$PATH#添加此行内容</span><br><span class="line"># User specific aliases and functions</span><br><span class="line"></span><br><span class="line">#6.刷新环境变量</span><br><span class="line">[hadoop@hadoop3 app]$ source ~/.bashrc</span><br></pre></td></tr></table></figure><h1 id="三、启动zookeeper"><a href="#三、启动zookeeper" class="headerlink" title="三、启动zookeeper"></a>三、启动zookeeper</h1><h2 id="hadoop1操作-2"><a href="#hadoop1操作-2" class="headerlink" title="hadoop1操作"></a>hadoop1操作</h2><h3 id="1-启动zookeeper"><a href="#1-启动zookeeper" class="headerlink" title="1.启动zookeeper"></a>1.启动zookeeper</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 app]$ cd /home/hadoop/app/zookeeper/bin/</span><br><span class="line">[hadoop@hadoop1 bin]$ ll</span><br><span class="line">总用量 36</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop  238 2月  20 2014 README.txt</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 1937 2月  20 2014 zkCleanup.sh</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 1049 2月  20 2014 zkCli.cmd</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 1534 2月  20 2014 zkCli.sh</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 1333 2月  20 2014 zkEnv.cmd</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 2696 2月  20 2014 zkEnv.sh</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 1084 2月  20 2014 zkServer.cmd</span><br><span class="line">-rwxr-xr-x. 1 hadoop hadoop 5742 2月  20 2014 zkServer.sh</span><br><span class="line"></span><br><span class="line">#启动zkServer.sh服务</span><br><span class="line">[hadoop@hadoop1 bin]$ ./zkServer.sh start</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /home/hadoop/app/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><h3 id="2-配置开机自启环境变量"><a href="#2-配置开机自启环境变量" class="headerlink" title="2.配置开机自启环境变量"></a>2.配置开机自启环境变量</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 init.d]$ sudo vi /etc/init.d/zookeeper#添加以下内容</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">#chkconfig:2345 20 90</span><br><span class="line">#description:zookeeper</span><br><span class="line">#processname:zookeeper</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/home/hadoop/app/jdk</span><br><span class="line">case $1 in</span><br><span class="line">        start) su root /home/hadoop/app/zookeeper/bin/zkServer.sh start;;</span><br><span class="line">        stop) su root /home/hadoop/app/zookeeper/bin/zkServer.sh stop;;</span><br><span class="line">        status) su root /home/hadoop/app/zookeeper/bin/zkServer.sh status;;</span><br><span class="line">        restart) su root /home/hadoop/app/zookeeper/bin/zkServer.sh restart;;</span><br><span class="line">        *)echo &quot;require start|stop|status|restart&quot;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="3-更改zookeeper权限"><a href="#3-更改zookeeper权限" class="headerlink" title="3.更改zookeeper权限"></a>3.更改zookeeper权限</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 init.d]$ sudo chmod +x /etc/init.d/zookeeper</span><br><span class="line">[hadoop@hadoop1 init.d]$ sudo chkconfig --add zookeeper</span><br><span class="line">[hadoop@hadoop1 init.d]$ sudo chkconfig zookeeper on#设置开机启动</span><br><span class="line">[hadoop@hadoop1 init.d]$ chkconfig --list#可以看到zookeeper已经添加到列表中</span><br><span class="line">注：该输出结果只显示 SysV 服务，并不包含</span><br><span class="line">原生 systemd 服务。SysV 配置数据</span><br><span class="line">可能被原生 systemd 配置覆盖。 </span><br><span class="line"></span><br><span class="line">      要列出 systemd 服务，请执行 &#x27;systemctl list-unit-files&#x27;。</span><br><span class="line">      查看在具体 target 启用的服务请执行</span><br><span class="line">      &#x27;systemctl list-dependencies [target]&#x27;。</span><br><span class="line"></span><br><span class="line">netconsole     0:关1:关2:关3:关4:关5:关6:关</span><br><span class="line">network        0:关1:关2:开3:开4:开5:开6:关</span><br><span class="line">zookeeper      0:关1:关2:开3:开4:开5:开6:关</span><br></pre></td></tr></table></figure><h3 id="4-将zookeeper文件夹拷贝到hadoop2和hadoop3"><a href="#4-将zookeeper文件夹拷贝到hadoop2和hadoop3" class="headerlink" title="4.将zookeeper文件夹拷贝到hadoop2和hadoop3"></a>4.将zookeeper文件夹拷贝到hadoop2和hadoop3</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 init.d]$ scp -r zookeeper root@hadoop2:/etc/init.d/</span><br><span class="line">[hadoop@hadoop1 init.d]$ scp -r zookeeper root@hadoop3:/etc/init.d/</span><br></pre></td></tr></table></figure><h2 id="hadoop2操作-2"><a href="#hadoop2操作-2" class="headerlink" title="hadoop2操作"></a>hadoop2操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop2 zkdatalog]$ cd /etc/init.d</span><br><span class="line">[hadoop@hadoop2 init.d]$ ll</span><br><span class="line">总用量 44</span><br><span class="line">-rw-r--r--. 1 root root 18281 5月  22 2020 functions</span><br><span class="line">-rwxr-xr-x. 1 root root  4569 5月  22 2020 netconsole</span><br><span class="line">-rwxr-xr-x. 1 root root  7928 5月  22 2020 network</span><br><span class="line">-rw-r--r--. 1 root root  1160 10月  2 2020 README</span><br><span class="line">-rwxr-xr-x. 1 root root   458 10月  8 21:52 zookeeper</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop2 init.d]$ sudo chkconfig --add zookeeper</span><br><span class="line">[hadoop@hadoop2 init.d]$ sudo chkconfig zookeeper on</span><br><span class="line">[hadoop@hadoop2 init.d]$  chkconfig --list#可以看到zookeeper已经添加到列表中</span><br><span class="line">注：该输出结果只显示 SysV 服务，并不包含</span><br><span class="line">原生 systemd 服务。SysV 配置数据</span><br><span class="line">可能被原生 systemd 配置覆盖。 </span><br><span class="line"></span><br><span class="line">      要列出 systemd 服务，请执行 &#x27;systemctl list-unit-files&#x27;。</span><br><span class="line">      查看在具体 target 启用的服务请执行</span><br><span class="line">      &#x27;systemctl list-dependencies [target]&#x27;。</span><br><span class="line"></span><br><span class="line">netconsole     0:关1:关2:关3:关4:关5:关6:关</span><br><span class="line">network        0:关1:关2:开3:开4:开5:开6:关</span><br><span class="line">zookeeper      0:关1:关2:开3:开4:开5:开6:关</span><br></pre></td></tr></table></figure><h2 id="hadoop3操作-2"><a href="#hadoop3操作-2" class="headerlink" title="hadoop3操作"></a>hadoop3操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop3 zkdatalog]$ cd /etc/init.d</span><br><span class="line">[hadoop@hadoop3 init.d]$ ll</span><br><span class="line">总用量 44</span><br><span class="line">-rw-r--r--. 1 root root 18281 5月  22 2020 functions</span><br><span class="line">-rwxr-xr-x. 1 root root  4569 5月  22 2020 netconsole</span><br><span class="line">-rwxr-xr-x. 1 root root  7928 5月  22 2020 network</span><br><span class="line">-rw-r--r--. 1 root root  1160 10月  2 2020 README</span><br><span class="line">-rwxr-xr-x. 1 root root   458 10月  8 21:52 zookeeper</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop3 init.d]$ sudo chkconfig --add zookeeper</span><br><span class="line">[sudo] hadoop 的密码：</span><br><span class="line">[hadoop@hadoop3 init.d]$ sudo chkconfig zookeeper on</span><br><span class="line">[hadoop@hadoop3 init.d]$ chkconfig --list</span><br><span class="line"></span><br><span class="line">注：该输出结果只显示 SysV 服务，并不包含</span><br><span class="line">原生 systemd 服务。SysV 配置数据</span><br><span class="line">可能被原生 systemd 配置覆盖。 </span><br><span class="line"></span><br><span class="line">      要列出 systemd 服务，请执行 &#x27;systemctl list-unit-files&#x27;。</span><br><span class="line">      查看在具体 target 启用的服务请执行</span><br><span class="line">      &#x27;systemctl list-dependencies [target]&#x27;。</span><br><span class="line"></span><br><span class="line">netconsole     0:关1:关2:关3:关4:关5:关6:关</span><br><span class="line">network        0:关1:关2:开3:开4:开5:开6:关</span><br><span class="line">zookeeper      0:关1:关2:开3:开4:开5:开6:关</span><br></pre></td></tr></table></figure><h3 id="4-分别切换hadoop1、2、3台主机"><a href="#4-分别切换hadoop1、2、3台主机" class="headerlink" title="4.分别切换hadoop1、2、3台主机"></a>4.分别切换hadoop1、2、3台主机</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 yxs]$ service zookeeper status#可以查看状态</span><br><span class="line">JMX enabled by default</span><br><span class="line">Using config: /home/hadoop/app/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower#有显示mode为开启成功</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop安装教程1</title>
      <link href="/posts/1a7a1840.html"/>
      <url>/posts/1a7a1840.html</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><p><div class="note info no-icon flat"><p>info 提示块标签</p></div></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">111</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><p><div class="note warning simple"><p>warning 提示块标签</p></div>=</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><details class="folding-tag"><summary> 查看图片测试 </summary>              <div class="content">              <p><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg" alt></p>              </div>            </details><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>待更新</p><h1 id="所需软件"><a href="#所需软件" class="headerlink" title="所需软件"></a>所需软件</h1><div class="note primary flat"><p>VMware虚拟机<br>Centos镜像<br>Xshell 用于连接虚拟机<br>Xftp7用于连接虚拟机传输文件<br>jdk-8u141-linux-x64.tar<br>zookeeper-3.4.6.tar<br>软件链接：链接：<a href="https://pan.baidu.com/s/10Qw0W9RfyFGHC971Q1_DPQ">https://pan.baidu.com/s/10Qw0W9RfyFGHC971Q1_DPQ</a><br>        提取码：vgha<br>Centos镜像：清华镜像站 <a href="https://mirror.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-2009.iso">https://mirror.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-2009.iso</a></p></div><h1 id="一、下载VMware"><a href="#一、下载VMware" class="headerlink" title="一、下载VMware"></a>一、下载VMware</h1><p>待更新</p><h1 id="二、-安装Centos"><a href="#二、-安装Centos" class="headerlink" title="二、    安装Centos"></a>二、    安装Centos</h1><p>待更新</p><h1 id="三、-配置网卡，确保能上网"><a href="#三、-配置网卡，确保能上网" class="headerlink" title="三、    配置网卡，确保能上网"></a>三、    配置网卡，确保能上网</h1><h2 id="（1）配置网卡"><a href="#（1）配置网卡" class="headerlink" title="（1）配置网卡"></a>（1）配置网卡</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[yxs@localhost ~]$ vi /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"></span><br><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line">BOOTPROTO=static        #将dhcp 改为static</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">IPV6_ADDR_GEN_MODE=stable-privacy</span><br><span class="line">NAME=ens33</span><br><span class="line">UUID=274191cd-5edc-4fd3-a9a7-9e8c1771821b</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes           #将no改为yes</span><br><span class="line">IPADDR=192.168.9.10#设置本机ip地址</span><br><span class="line">GATEWAY=192.168.9.254#默认网关，要跟设置的网关一样</span><br><span class="line">NETMASK=255.255.255.0#默认为255.255.255.0</span><br><span class="line">DNS1=8.8.8.8#添加DNS1</span><br><span class="line">DNS2=114.114.114.114#添加DNS2</span><br></pre></td></tr></table></figure><h2 id="（2）重启网卡，ping百度测试网络，ping通则为设置成功"><a href="#（2）重启网卡，ping百度测试网络，ping通则为设置成功" class="headerlink" title="（2）重启网卡，ping百度测试网络，ping通则为设置成功"></a>（2）重启网卡，ping百度测试网络，ping通则为设置成功</h2><h3 id="重启网卡"><a href="#重启网卡" class="headerlink" title="重启网卡"></a>重启网卡</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# service network restart</span><br><span class="line">Restarting network (via systemctl):                        [  确定  ]</span><br></pre></td></tr></table></figure><h3 id="ping-百度"><a href="#ping-百度" class="headerlink" title="ping 百度"></a>ping 百度</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# ping www.baidu.com#以下代码为网络正常</span><br><span class="line">PING www.a.shifen.com (14.215.177.38) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=1 ttl=128 time=280 ms</span><br><span class="line">64 bytes from 14.215.177.38 (14.215.177.38): icmp_seq=2 ttl=128 time=6.17 ms</span><br></pre></td></tr></table></figure><h1 id="四、-配置yum源"><a href="#四、-配置yum源" class="headerlink" title="四、    配置yum源"></a>四、    配置yum源</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS7-dns-hadoop1 ~]# sudo curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#方法一</span><br><span class="line"></span><br><span class="line">[root@CentOS7-dns-hadoop1 ~]# sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo#方法二</span><br><span class="line">这里也可以用 wget，推荐使用 curl方法一， 因为有些最小化安装的 centos 默认不带 wget，上下两条命令选择一条即可</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#清理缓存</span><br><span class="line">[root@CentOS7-dns-hadoop1 ~]# sudo yum clean all</span><br><span class="line"></span><br><span class="line">#在本地索引缓存</span><br><span class="line">[root@CentOS7-dns-hadoop1 ~]# sudo yum makecache</span><br><span class="line"></span><br><span class="line">#查看更换的源</span><br><span class="line">[root@localhost yxs]# yum repolist#下面源名称为aliyun则更换yum源成功</span><br><span class="line">已加载插件：fastestmirror</span><br><span class="line">Loading mirror speeds from cached hostfile</span><br><span class="line"> * base: mirrors.aliyun.com</span><br><span class="line"> * extras: mirrors.aliyun.com</span><br><span class="line"> * updates: mirrors.aliyun.com</span><br><span class="line">源标识            源名称                                          状态</span><br><span class="line">base/7/x86_64     CentOS-7 - Base - mirrors.aliyun.com               10,072</span><br><span class="line">extras/7/x86_64    CentOS-7 - Extras - mirrors.aliyun.com                516</span><br><span class="line">updates/7/x86_64   CentOS-7 - Updates - mirrors.aliyun.com            4,244</span><br><span class="line">repolist: 14,832</span><br></pre></td></tr></table></figure><h1 id="五、-关闭防火墙"><a href="#五、-关闭防火墙" class="headerlink" title="五、    关闭防火墙"></a>五、    关闭防火墙</h1><div class="note info flat"><p><strong>停止防火墙</strong></p></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# systemctl stop firewalld</span><br></pre></td></tr></table></figure><div class="note info flat"><p><strong>关闭防火墙开机自启</strong></p></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# systemctl disable firewalld</span><br><span class="line">Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.</span><br><span class="line">Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</span><br></pre></td></tr></table></figure><div class="note info flat"><p><strong>查看防火墙状态，显示灰且 Active: inactive (dead)为防火墙关闭状态</strong></p></div><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# systemctl status firewalld</span><br><span class="line">● firewalld.service - firewalld - dynamic firewall daemon</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)</span><br><span class="line">   Active: inactive (dead)</span><br><span class="line">     Docs: man:firewalld(1)</span><br><span class="line"></span><br><span class="line">10月 04 05:06:20 localhost.localdomain systemd[1]: Starting firewalld - dynami...</span><br><span class="line">10月 04 05:06:21 localhost.localdomain systemd[1]: Started firewalld - dynamic...</span><br><span class="line">10月 04 05:06:21 localhost.localdomain firewalld[738]: WARNING: AllowZoneDrift...</span><br><span class="line">10月 03 21:40:06 localhost.localdomain systemd[1]: Stopping firewalld - dynami...</span><br><span class="line">10月 03 21:40:06 localhost.localdomain systemd[1]: Stopped firewalld - dynamic...</span><br><span class="line">Hint: Some lines were ellipsized, use -l to show in full.</span><br></pre></td></tr></table></figure><h1 id="六、-克隆hadoop镜像"><a href="#六、-克隆hadoop镜像" class="headerlink" title="六、    克隆hadoop镜像"></a>六、    克隆hadoop镜像</h1><p>待更新</p><h1 id="七、-配置主机名与IP映射"><a href="#七、-配置主机名与IP映射" class="headerlink" title="七、    配置主机名与IP映射"></a>七、    配置主机名与IP映射</h1><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab active"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content" id="1-1"><p><div class="note info no-icon flat"><p><strong>配置IP映射（hadoop1、hadoop2、hadoop3每个节点都需修改）</strong></p></div></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# vi /etc/hostname</span><br><span class="line">hadoop1    修改为hadoop1，：wq保存</span><br><span class="line"></span><br><span class="line">[yxs@hadoop1 ~]$ hostname    #重启主机后可以查看主机名</span><br><span class="line">hadoop1</span><br><span class="line"></span><br><span class="line">[yxiansen@hadoop1 ~]$ vi /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.9.10 hadoop1        #添加ip映射，注意ip地址为你每个hadoop的ip地址</span><br><span class="line">192.168.9.20 hadoop2        #添加ip映射</span><br><span class="line">192.168.9.30 hadoop3        #添加ip映射</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content active" id="1-2"><p><div class="note info no-icon flat"><p><strong>配置IP映射（hadoop1、hadoop2、hadoop3每个节点都需修改）</strong></p></div></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# vi /etc/hostname</span><br><span class="line">hadoop2    修改为hadoop2，：wq保存</span><br><span class="line"></span><br><span class="line">[yxs@hadoop2 ~]$ hostname    #重启主机后可以查看主机名</span><br><span class="line">hadoop2</span><br><span class="line"></span><br><span class="line">[yxs@hadoop2 ~]$ vi /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.9.10 hadoop1        #添加ip映射，注意ip地址为你每个hadoop的ip地址</span><br><span class="line">192.168.9.20 hadoop2        #添加ip映射</span><br><span class="line">192.168.9.30 hadoop3        #添加ip映射</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><p><div class="note info no-icon flat"><p><strong>配置IP映射（hadoop1、hadoop2、hadoop3每个节点都需修改）</strong></p></div></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost yxs]# vi /etc/hostname</span><br><span class="line">hadoop3    修改为hadoop3，：wq保存</span><br><span class="line"></span><br><span class="line">[yxs@hadoop3 ~]$ hostname    #重启主机后可以查看主机名</span><br><span class="line">hadoop3</span><br><span class="line"></span><br><span class="line">[yxs@hadoop3 ~]$ vi /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.9.10 hadoop1        #添加ip映射，注意ip地址为你每个hadoop的ip地址</span><br><span class="line">192.168.9.20 hadoop2        #添加ip映射</span><br><span class="line">192.168.9.30 hadoop3        #添加ip映射</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><h1 id="八、-用户和用户组操作"><a href="#八、-用户和用户组操作" class="headerlink" title="八、    用户和用户组操作"></a>八、    用户和用户组操作</h1><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#创建新用户</span><br><span class="line">[root@hadoop1 yxs]# useradd hadoop</span><br><span class="line"></span><br><span class="line">#设置新用户密码</span><br><span class="line">[root@hadoop1 yxs]# passwd hadoop</span><br><span class="line">更改用户 hadoop 的密码 。</span><br><span class="line">新的 密码：</span><br><span class="line">无效的密码： 密码少于 8 个字符</span><br><span class="line">重新输入新的 密码：</span><br><span class="line">passwd：所有的身份验证令牌已经成功更新。</span><br><span class="line"></span><br><span class="line">#查询新建的用户组</span><br><span class="line">[root@hadoop1 yxs]# id hadoop</span><br><span class="line">uid=1001(hadoop) gid=1001(hadoop) 组=1001(hadoop)</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#创建新用户</span><br><span class="line">[root@hadoop2 yxs]# useradd hadoop</span><br><span class="line"></span><br><span class="line">#设置新用户密码</span><br><span class="line">[root@hadoop2 yxs]# passwd hadoop</span><br><span class="line">更改用户 hadoop 的密码 。</span><br><span class="line">新的 密码：</span><br><span class="line">无效的密码： 密码少于 8 个字符</span><br><span class="line">重新输入新的 密码：</span><br><span class="line">passwd：所有的身份验证令牌已经成功更新。</span><br><span class="line"></span><br><span class="line">#查询新建的用户组</span><br><span class="line">[root@hadoop2 yxs]# id hadoop</span><br><span class="line">uid=1001(hadoop) gid=1001(hadoop) 组=1001(hadoop)</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#创建新用户</span><br><span class="line">[root@hadoop3 yxs]# useradd hadoop</span><br><span class="line"></span><br><span class="line">#设置新用户密码</span><br><span class="line">[root@hadoop3 yxs]# passwd hadoop</span><br><span class="line">更改用户 hadoop 的密码 。</span><br><span class="line">新的 密码：</span><br><span class="line">无效的密码： 密码少于 8 个字符</span><br><span class="line">重新输入新的 密码：</span><br><span class="line">passwd：所有的身份验证令牌已经成功更新。</span><br><span class="line"></span><br><span class="line">#查询新建的用户组</span><br><span class="line">[root@hadoop3 yxs]# id hadoop</span><br><span class="line">uid=1001(hadoop) gid=1001(hadoop) 组=1001(hadoop)</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><h1 id="九、-给普通用户授权root权限"><a href="#九、-给普通用户授权root权限" class="headerlink" title="九、    给普通用户授权root权限"></a>九、    给普通用户授权root权限</h1><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.#进入root超级用户，修改sudoers文件</span><br><span class="line">[root@hadoop1 ~]# cd /etc</span><br><span class="line">[root@hadoop1 etc]# ll</span><br><span class="line">-r--r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#找到sudoers文件，会发现文件权限是只读，所以我们需要用chmod修改权限</span><br><span class="line"></span><br><span class="line">2.#修改sudoers权限</span><br><span class="line">[root@hadoop1 etc]# chmod 640 sudoers</span><br><span class="line">[root@hadoop1 etc]# ll</span><br><span class="line">-rw-r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#文件权限变为可读写</span><br><span class="line"></span><br><span class="line">3.#修改sudoers文件</span><br><span class="line">[root@hadoop1 etc]# vi /etc/sudoers</span><br><span class="line">#找到以下内容，添加第三行 root    ALL=(ALL)       ALL</span><br><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop    ALL=(ALL)       ALL        #添加此行代码</span><br><span class="line"></span><br><span class="line">4.#将sudoers权限改回</span><br><span class="line">[root@hadoop1 etc]# chmod 440 sudoers</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.#进入root超级用户，修改sudoers文件</span><br><span class="line">[root@hadoop2 ~]# cd /etc</span><br><span class="line">[root@hadoop2 etc]# ll</span><br><span class="line">-r--r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#找到sudoers文件，会发现文件权限是只读，所以我们需要用chmod修改权限</span><br><span class="line"></span><br><span class="line">2.#修改sudoers权限</span><br><span class="line">[root@hadoop2 etc]# chmod 640 sudoers</span><br><span class="line">[root@hadoop2 etc]# ll</span><br><span class="line">-rw-r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#文件权限变为可读写</span><br><span class="line"></span><br><span class="line">3.#修改sudoers文件</span><br><span class="line">[root@hadoop2 etc]# vi /etc/sudoers</span><br><span class="line">#找到以下内容，添加第三行 root    ALL=(ALL)       ALL</span><br><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop    ALL=(ALL)       ALL        #添加此行代码</span><br><span class="line"></span><br><span class="line">4.#将sudoers权限改回</span><br><span class="line">[root@hadoop2 etc]# chmod 440 sudoers</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1.#进入root超级用户，修改sudoers文件</span><br><span class="line">[root@hadoop3 ~]# cd /etc</span><br><span class="line">[root@hadoop3 etc]# ll</span><br><span class="line">-r--r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#找到sudoers文件，会发现文件权限是只读，所以我们需要用chmod修改权限</span><br><span class="line"></span><br><span class="line">2.#修改sudoers权限</span><br><span class="line">[root@hadoop3 etc]# chmod 640 sudoers</span><br><span class="line">[root@hadoop3 etc]# ll</span><br><span class="line">-rw-r-----. 1 root root  4328 9月  30 2020 sudoers</span><br><span class="line">#文件权限变为可读写</span><br><span class="line"></span><br><span class="line">3.#修改sudoers文件</span><br><span class="line">[root@hadoop3 etc]# vi /etc/sudoers</span><br><span class="line">#找到以下内容，添加第三行 root    ALL=(ALL)       ALL</span><br><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop    ALL=(ALL)       ALL        #添加此行代码</span><br><span class="line"></span><br><span class="line">4.#将sudoers权限改回</span><br><span class="line">[root@hadoop3 etc]# chmod 440 sudoers</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><h1 id="十、-配置SSH免密登录"><a href="#十、-配置SSH免密登录" class="headerlink" title="十、    配置SSH免密登录"></a>十、    配置SSH免密登录</h1><div class="note info no-icon flat"><p><strong>(1)配置免密登录</strong></p></div><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.以hadoop普通用户为例 进入hadoop用户命令：su hadoop</span><br><span class="line">[yxs@hadoop1 etc]$ su hadoop</span><br><span class="line"></span><br><span class="line">2.ssh-keygen 用来生成 RSA类型的密钥以及管理该密钥,参数“-t”用于指定要创建的 SSH 密钥的类型为RSA。</span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh-keygen -t rsa    #需按回车三次</span><br><span class="line"></span><br><span class="line">3.用 ssh-copy-id 将公钥复制到hadoop1、hadoop2、hadoop3虚拟机中</span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh-copy-id hadoop1</span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh-copy-id hadoop2</span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh-copy-id hadoop3</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1.    以hadoop普通用户为例 进入hadoop用户命令：su hadoop</span><br><span class="line">[yxs@hadoop2 etc]$ su hadoop</span><br><span class="line"></span><br><span class="line">2.ssh-keygen 用来生成 RSA类型的密钥以及管理该密钥,参数“-t”用于指定要创建的 SSH 密钥的类型为RSA。</span><br><span class="line">[hadoop@hadoop2 yxs]$ ssh-keygen -t rsa    #需按回车三次</span><br><span class="line"></span><br><span class="line">3.用 ssh-copy-id 将公钥复制到hadoop1、hadoop2、hadoop3虚拟机中</span><br><span class="line">[hadoop@hadoop2 yxs]$ ssh-copy-id hadoop1</span><br><span class="line">[hadoop@hadoop2 yxs]$ ssh-copy-id hadoop2</span><br><span class="line">[hadoop@hadoop2 yxs]$ ssh-copy-id hadoop3</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh hadoop1    # 登录hadoop1，没有输入密码就是设置成功</span><br><span class="line">Last login: Tue Oct  4 10:34:31 2022</span><br><span class="line">[hadoop@hadoop1 ~]$ exit    #退出登录</span><br><span class="line">Connection to hadoop1 closed.</span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop2        #登录hadoop2</span><br><span class="line">Last login: Tue Oct  4 13:38:03 2022</span><br><span class="line">[hadoop@hadoop2 ~]$ exit                #退出登录</span><br><span class="line">登出</span><br><span class="line">Connection to hadoop2 closed.</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.    以hadoop普通用户为例 进入hadoop用户命令：su hadoop</span><br><span class="line">[yxs@hadoop3 etc]$ su hadoop</span><br><span class="line"></span><br><span class="line">2.ssh-keygen 用来生成 RSA类型的密钥以及管理该密钥,参数“-t”用于指定要创建的 SSH 密钥的类型为RSA。</span><br><span class="line">[hadoop@hadoop3 yxs]$ ssh-keygen -t rsa    #需按回车三次</span><br><span class="line"></span><br><span class="line">3.用 ssh-copy-id 将公钥复制到hadoop1、hadoop2、hadoop3虚拟机中</span><br><span class="line">[hadoop@hadoop3 yxs]$ ssh-copy-id hadoop1</span><br><span class="line">[hadoop@hadoop3 yxs]$ ssh-copy-id hadoop2</span><br><span class="line">[hadoop@hadoop3 yxs]$ ssh-copy-id hadoop3</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><div class="note info no-icon flat"><p><strong>(2)测试免密登录</strong></p></div><h3 id="切换回hadoop1，ssh免密登录第一次需要可能密码"><a href="#切换回hadoop1，ssh免密登录第一次需要可能密码" class="headerlink" title="切换回hadoop1，ssh免密登录第一次需要可能密码"></a>切换回hadoop1，ssh免密登录第一次需要可能密码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 yxs]$ ssh hadoop1# 登录hadoop1，没有输入密码就是设置成功</span><br><span class="line">Last login: Tue Oct  4 10:34:31 2022</span><br><span class="line">[hadoop@hadoop1 ~]$ exit    #退出登录</span><br><span class="line">Connection to hadoop1 closed.</span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop2#登录hadoop2</span><br><span class="line">Last login: Tue Oct  4 13:38:03 2022</span><br><span class="line">[hadoop@hadoop2 ~]$ exit#退出登录</span><br><span class="line">登出</span><br><span class="line">Connection to hadoop2 closed.</span><br><span class="line">[hadoop@hadoop1 yxs]$ ssh hadoop3#登录hadoop3</span><br><span class="line">Last login: Tue Oct  4 13:39:19 2022</span><br><span class="line">[hadoop@hadoop3 ~]$ exit#退出登录</span><br><span class="line">登出</span><br><span class="line">Connection to hadoop3 closed.</span><br></pre></td></tr></table></figure><h1 id="十一、创建规划目录"><a href="#十一、创建规划目录" class="headerlink" title="十一、创建规划目录"></a>十一、创建规划目录</h1><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#以普通用户登录（命令：su hadoop），创建app、tools、data目录</span><br><span class="line">[hadoop@hadoop1 yxs]$ cd /home/hadoop   #进入hadoop</span><br><span class="line">[hadoop@hadoop1 hadoop]$ mkdir app            #创建app目录</span><br><span class="line">[hadoop@hadoop1 hadoop]$ mkdir tools        #创建tools目录</span><br><span class="line">[hadoop@hadoop1 hadoop]$ mkdir data            #创建data目录</span><br><span class="line">[hadoop@hadoop1 hadoop]$ ll                    #查看目录文件</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 5 hadoop hadoop 202 10月  9 22:48 app</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop  44 10月  9 23:03 data</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   6 10月  4 13:55 tools</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#以普通用户登录（命令：su hadoop），创建app、tools、data目录</span><br><span class="line">[hadoop@hadoop2 yxs]$ cd /home/hadoop   #进入hadoop</span><br><span class="line">[hadoop@hadoop2 hadoop]$ mkdir app            #创建app目录</span><br><span class="line">[hadoop@hadoop2 hadoop]$ mkdir tools        #创建tools目录</span><br><span class="line">[hadoop@hadoop2 hadoop]$ mkdir data        #创建data目录</span><br><span class="line">[hadoop@hadoop2 hadoop]$ ll                #查看目录文件</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 5 hadoop hadoop 202 10月  9 22:48 app</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop  44 10月  9 23:03 data</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   6 10月  4 13:55 tools</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#以普通用户登录（命令：su hadoop），创建app、tools、data目录</span><br><span class="line">[hadoop@hadoop3 yxs]$ cd /home/hadoop   #进入hadoop</span><br><span class="line">[hadoop@hadoop3 hadoop]$ mkdir app            #创建app目录</span><br><span class="line">[hadoop@hadoop3 hadoop]$ mkdir tools        #创建tools目录</span><br><span class="line">[hadoop@hadoop3 hadoop]$ mkdir data        #创建data目录</span><br><span class="line">[hadoop@hadoop3 hadoop]$ ll                #查看目录文件</span><br><span class="line">总用量 0</span><br><span class="line">drwxrwxr-x. 5 hadoop hadoop 202 10月  9 22:48 app</span><br><span class="line">drwxrwxr-x. 4 hadoop hadoop  44 10月  9 23:03 data</span><br><span class="line">drwxrwxr-x. 2 hadoop hadoop   6 10月  4 13:55 tools</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div><h1 id="十二、配置NTP时钟同步"><a href="#十二、配置NTP时钟同步" class="headerlink" title="十二、配置NTP时钟同步"></a>十二、配置NTP时钟同步</h1><div class="tabs" id="1"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#1-1">hadoop1操作</button></li><li class="tab"><button type="button" data-href="#1-2">hadoop2操作</button></li><li class="tab"><button type="button" data-href="#1-3">hadoop3操作</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="1-1"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">1.给hadoop1安装ntp</span><br><span class="line">[root@hadoop1 hadoop]# rpm -qa | grep ntp    #查看是否安装ntp</span><br><span class="line">[root@hadoop1 hadoop]# yum -y install ntp    #安装ntp</span><br><span class="line"></span><br><span class="line">2.编辑hadoop1  ntp配置文件</span><br><span class="line">[root@hadoop1 hadoop]# vi /etc/ntp.conf        #编辑ntp文件</span><br><span class="line"># For more information about this file, see the man pages</span><br><span class="line"># ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"></span><br><span class="line"># Permit time synchronization with our time source, but do not</span><br><span class="line"># permit the source to query or modify the service on this system.</span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line"># Permit all access over the loopback interface.  This could</span><br><span class="line"># be tightened as well, but to do so would effect some of</span><br><span class="line"># the administrative functions.</span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"></span><br><span class="line"># Hosts on local network are less restricted.</span><br><span class="line">restrict 192.168.9.10 mask 255.255.255.0 nomodify notrap 将ip地址改为hadoop1的ip地址192.168.xx.xx</span><br><span class="line"></span><br><span class="line"># Use public servers from the pool.ntp.org project.</span><br><span class="line"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span><br><span class="line">#server 0.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 1.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 2.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 3.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">server 127.127.1.0                #添加此行</span><br><span class="line">fudge 127.127.1.0 stratum 10            #添加此行</span><br><span class="line"></span><br><span class="line">#broadcast 192.168.1.255 autokey        # broadcast server</span><br><span class="line">#broadcastclient                        # broadcast client</span><br><span class="line">#broadcast 224.0.1.1 autokey            # multicast server</span><br><span class="line">#multicastclient 224.0.1.1              # multicast client</span><br><span class="line">#manycastserver 239.255.254.254         # manycast server</span><br><span class="line">#manycastclient 239.255.254.254 autokey # manycast client</span><br><span class="line"></span><br><span class="line"># Enable public key cryptography.</span><br><span class="line">#crypto</span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line"># Key file containing the keys and key identifiers used when operating</span><br><span class="line"># with symmetric key cryptography.</span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line"></span><br><span class="line"># Specify the key identifiers which are trusted.</span><br><span class="line">#trustedkey 4 8 42</span><br><span class="line"></span><br><span class="line">#：wq保存数据</span><br><span class="line"></span><br><span class="line">3.开启ntp</span><br><span class="line">[root@hadoop1 hadoop]# service ntpd start</span><br><span class="line">Redirecting to /bin/systemctl start ntpd.service</span><br><span class="line"></span><br><span class="line">4.#设置ntp开机启动</span><br><span class="line">[root@hadoop1 hadoop]# chkconfig ntpd on</span><br><span class="line">注意：正在将请求转发到“systemctl enable ntpd.service”。</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br><span class="line"></span><br><span class="line">5.#查看ntp开启状态</span><br><span class="line">[root@hadoop1 hadoop]# service ntpd status</span><br><span class="line"></span><br><span class="line">6.#同步ntpdate主节点</span><br><span class="line">[root@hadoop1 hadoop]# ntpdate hadoop1        </span><br><span class="line"></span><br><span class="line">7.ntpq -p 可查看NTP服务器的列表</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-2"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">1.给hadoop2安装ntp</span><br><span class="line">[root@hadoop2 hadoop]# rpm -qa | grep ntp    #查看是否安装ntp</span><br><span class="line">[root@hadoop2 hadoop]# yum -y install ntp    #安装ntp</span><br><span class="line"></span><br><span class="line">2.编辑hadoop2  ntp配置文件</span><br><span class="line">[root@hadoop2 hadoop]# vi /etc/ntp.conf        #编辑ntp文件</span><br><span class="line"># For more information about this file, see the man pages</span><br><span class="line"># ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"></span><br><span class="line"># Permit time synchronization with our time source, but do not</span><br><span class="line"># permit the source to query or modify the service on this system.</span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line"># Permit all access over the loopback interface.  This could</span><br><span class="line"># be tightened as well, but to do so would effect some of</span><br><span class="line"># the administrative functions.</span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"></span><br><span class="line"># Hosts on local network are less restricted.</span><br><span class="line">restrict 192.168.9.10 mask 255.255.255.0 nomodify notrap 将ip地址改为hadoop1的ip地址192.168.xx.xx</span><br><span class="line"></span><br><span class="line"># Use public servers from the pool.ntp.org project.</span><br><span class="line"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span><br><span class="line">#server 0.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 1.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 2.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 3.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">server 127.127.1.0                #添加此行</span><br><span class="line">fudge 127.127.1.0 stratum 10            #添加此行</span><br><span class="line"></span><br><span class="line">#broadcast 192.168.1.255 autokey        # broadcast server</span><br><span class="line">#broadcastclient                        # broadcast client</span><br><span class="line">#broadcast 224.0.1.1 autokey            # multicast server</span><br><span class="line">#multicastclient 224.0.1.1              # multicast client</span><br><span class="line">#manycastserver 239.255.254.254         # manycast server</span><br><span class="line">#manycastclient 239.255.254.254 autokey # manycast client</span><br><span class="line"></span><br><span class="line"># Enable public key cryptography.</span><br><span class="line">#crypto</span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line"># Key file containing the keys and key identifiers used when operating</span><br><span class="line"># with symmetric key cryptography.</span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line"></span><br><span class="line"># Specify the key identifiers which are trusted.</span><br><span class="line">#trustedkey 4 8 42</span><br><span class="line">#：wq保存数据</span><br><span class="line"></span><br><span class="line">3.开启ntp</span><br><span class="line">[root@hadoop2 hadoop]# service ntpd start</span><br><span class="line">Redirecting to /bin/systemctl start ntpd.service</span><br><span class="line"></span><br><span class="line">4.#设置ntp开机启动</span><br><span class="line">[root@hadoop2 hadoop]# chkconfig ntpd on</span><br><span class="line">注意：正在将请求转发到“systemctl enable ntpd.service”。</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br><span class="line"></span><br><span class="line">#查看ntp开启状态</span><br><span class="line">5.[root@hadoop2 hadoop]# service ntpd status</span><br><span class="line"></span><br><span class="line">6.#同步ntpdate主节点</span><br><span class="line">[root@hadoop2 hadoop]# ntpdate hadoop1        </span><br><span class="line"></span><br><span class="line">7.ntpq -p 可查看NTP服务器的列表</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="1-3"><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">1.给hadoop2安装ntp</span><br><span class="line">[root@hadoop3 hadoop]# rpm -qa | grep ntp    #查看是否安装ntp</span><br><span class="line">[root@hadoop3 hadoop]# yum -y install ntp    #安装ntp</span><br><span class="line"></span><br><span class="line">2.编辑hadoop3  ntp配置文件</span><br><span class="line">[root@hadoop3 hadoop]# vi /etc/ntp.conf        #编辑ntp文件</span><br><span class="line"># For more information about this file, see the man pages</span><br><span class="line"># ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span><br><span class="line"></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"></span><br><span class="line"># Permit time synchronization with our time source, but do not</span><br><span class="line"># permit the source to query or modify the service on this system.</span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"></span><br><span class="line"># Permit all access over the loopback interface.  This could</span><br><span class="line"># be tightened as well, but to do so would effect some of</span><br><span class="line"># the administrative functions.</span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"></span><br><span class="line"># Hosts on local network are less restricted.</span><br><span class="line">restrict 192.168.9.10 mask 255.255.255.0 nomodify notrap 将ip地址改为hadoop1的ip地址192.168.xx.xx</span><br><span class="line"></span><br><span class="line"># Use public servers from the pool.ntp.org project.</span><br><span class="line"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span><br><span class="line">#server 0.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 1.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 2.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">#server 3.centos.pool.ntp.org iburst    #注释此行</span><br><span class="line">server 127.127.1.0                #添加此行</span><br><span class="line">fudge 127.127.1.0 stratum 10            #添加此行</span><br><span class="line"></span><br><span class="line">#broadcast 192.168.1.255 autokey        # broadcast server</span><br><span class="line">#broadcastclient                        # broadcast client</span><br><span class="line">#broadcast 224.0.1.1 autokey            # multicast server</span><br><span class="line">#multicastclient 224.0.1.1              # multicast client</span><br><span class="line">#manycastserver 239.255.254.254         # manycast server</span><br><span class="line">#manycastclient 239.255.254.254 autokey # manycast client</span><br><span class="line"></span><br><span class="line"># Enable public key cryptography.</span><br><span class="line">#crypto</span><br><span class="line"></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"></span><br><span class="line"># Key file containing the keys and key identifiers used when operating</span><br><span class="line"># with symmetric key cryptography.</span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line"></span><br><span class="line"># Specify the key identifiers which are trusted.</span><br><span class="line">#trustedkey 4 8 42</span><br><span class="line"></span><br><span class="line">#：wq保存数据</span><br><span class="line"></span><br><span class="line">3.开启ntp</span><br><span class="line">[root@hadoop1 hadoop]# service ntpd start</span><br><span class="line">Redirecting to /bin/systemctl start ntpd.service</span><br><span class="line"></span><br><span class="line">4.#设置ntp开机启动</span><br><span class="line">[root@hadoop1 hadoop]# chkconfig ntpd on</span><br><span class="line">注意：正在将请求转发到“systemctl enable ntpd.service”。</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/ntpd.service to /usr/lib/systemd/system/ntpd.service.</span><br><span class="line"></span><br><span class="line">#查看ntp开启状态</span><br><span class="line">5.[root@hadoop1 hadoop]# service ntpd status</span><br><span class="line"></span><br><span class="line">6.#同步ntpdate主节点</span><br><span class="line">[root@hadoop2 hadoop]# ntpdate hadoop1        </span><br><span class="line"></span><br><span class="line">7.ntpq -p 可查看NTP服务器的列表</span><br></pre></td></tr></table></figure><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>]]></content>
      
      
      
        <tags>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
